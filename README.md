Data processing codes for ArGSet. 

**About ArGSet**
Argon Gas Setup for measurement of wavelength shifting materials at cryogenic temperature.\
[Learn about ArGSet here](https://gitlab.camk.edu.pl/mkuzniak/cezamat/-/wikis/ArgSet)

**Repository structure:**\
Legacy directory is for old code. It is kept only for archival purpose.

**Requirements**\
To satify all requirements do these:
1. rename jar_*.yml to jar.yml
2. edit jar.yml to change prefix a/c to your miniconda installation.
3. `conda env create -f jar.yml`
4. This will not install peakdetect package which needs to be installed via pip. Also, peakdetect is outdated package, its source code needs to tweaked slightly to make use of newer versions of scipy FFT. Pyreco has separate installation steps. See [pyreco repository](https://gitlab.camk.edu.pl/mkuzniak/pyreco).

**Computing resources:**\
wf search script consumes a lot of computing resources, it should only be executed on an interactive node or submitted as a slurm job.\
<span style="color: yellow"> Warning: </span> The code probably won't be able to complete execution on a login node. This is your only warning!

**Data Processing:**\
There are several tools available for data processing:
- create_event_catalogue.py\
    Expects midas data files as input. Writes a pickle file containing event catalogues for each channel.
- calculate_pulse_param.py\
    Does all processing from finding clean waveforms to fitting with SiPM pulse model. Writes results to pickle files.
- notebooks/histogram_pulse_param.ipynb
    - Channelwise concatenation of events from several runs
    - Performs histogramming on fit parameters, applies cut, and fits gaussian to the resultant histogram.
    - Makes Fingerplots from concatenated fit catalogues. The instructions for generating finger plots will be provided in a separate document.

**Catalogue:**\
The eventwise data products are catalogued in form of pandas DataFrames. I call these catalogues. The catalogue for all channels are packaged together as a python dict and written to disk as pickle file.\
There are three different types of catalogues generated by these codes: 
- event catalogue: it contains waveforms in a DataFrame. *Future:* I will explore the option to save these as numpy compressed array (.npz) files instead.
- clean catalogue: contains list of events deemed to be clean along with estimated peak location. The precise definition of clean event is defined within the script, but it means an event with only one prominent pulse.
- fit catalogue: contains list of clean event along with SiPM pulse model parameters. The event for which model parameters could not be estimated contain a none object in fit_param column instead. 

**Pickle files:**\
Pickle is a data serialization format for python objects. Pickle files are neither secure nor memory efficient. Pickle files should never be used for sharing data. *Future:* I will explore alternatives to pickle files.
